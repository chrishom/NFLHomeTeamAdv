---
title: "Regression Analyisis of 'Home-Team Advantage' in the National Football League"
author: "Christopher Hom, Joanna Rashid, Lili Teister, Stephen Yu"
date: "04/27/2022"
geometry: margin=1cm
output: 
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

Is “home team advantage” a statistically significant phenomenon in the National Football League (NFL)?  If so, what variables in the data can explain this phenomenon? Linear and logistic regression are used to explore the relationship of various game data features on game outcomes. We attempt to control for variables that impact the expected result of a game and identify if there remains any additional advantage for the home team.

The phenomena of home-field-advantage is well documented (Swartz, T. B. et al., Jamieson, J. P.) Review of Cleveland, et al., Swartz, T. B., et al. contributed to rigorous selection and computation of control variables. However, there is evidence that the home-field advantage effect is shrinking (Kilgore, A., & Greenberg, N.), even more so in the age of the pandemic where some games are played with no fans in the stands (Ponzo, M., et al., Mccarrick, D et al.).

For this analysis, multiple data sets have been joined to produce both factor and continuous variables related to a game’s time, location, and conditions as well as a team’s injuries, amount of rest, distance traveled, and relative ability. These variables are regressed on the spread of the score where negative values indicate a home team loss. Additionally, we have implemented a logistic regression model wherein the same explanatory variables are used to explain the log-likelihood of a home-team win. A random forest model is also implemented to explore relative variable importance. 
.
# Analysis

### Required packages

```{r, echo = TRUE, warning=FALSE}
#install.packages("tidyverse")
#install.packages()
#install.packages("devtools")
#devtools::install_github(repo = "maksimhorowitz/nflscrapR")
#install.packages("nflreadr")
#install.packages("car")
```

```{r, message = FALSE}
#library(nflscrapR)
library(dplyr)
library(nflreadr)
library(ggplot2)
library(car)
library(lubridate)
library(tidyverse)
library(caret)
library(caTools)
library(randomForest)
```

## Data

### Games dataset

The games dataset is the main dataset that will be used for analysis. It contains a row for each NFL games from 1999 to 2021, but only seasons from 2010 to 2019 will be included in the analysis. Also, pre-season games are not included in the analysis.

```{r}
games_raw <- read.csv("http://www.habitatring.com/games.csv") %>%
  filter(season > 2009)
```

First, various attributes were selected to use as potential predicting or response variables.

One of those variables is `moneyline`, a betting wager, which can be converted with the following formula into the win probability based on bets placed before the game. `Spread_line` is another useful variable based on betting odds that is used to even out two uneven teams. Both of these variables are driven by advanced analytics and actual wagering, so they are complex and _do_ account for any believed effect of the home team advantage. According to [sports news outlets](https://www.cbssports.com/nfl/news/nfl-betting-tips-how-much-home-field-advantage-is-worth-for-every-nfl-team-in-2019/), generally, this accounts for as many as 3 but more realistically 1-2 spread points. 

```{r}
moneyline_to_odds_for <- function(ml){
  ifelse(ml < 0, (0-ml) / (0-ml+100), 100/(ml+100))
}
```

```{r}
games_select <- games_raw %>%
  mutate(home_prob = moneyline_to_odds_for(home_moneyline)) %>%
  select(game_id, # identifier for the game
         season, # year of season start
         game_type, # regular season, playoff game, etc
         week, # week number during the season
         gameday, # date of game
         weekday, # day of the week of the game, usually Sunday, Monday, or Thursday
         gametime, # time of the start of the game, eastern time
         away_team, # abbreviation for the away team
         home_team, # abbreviation for the home team
         home_score, # final score for the home team
         away_score, # final score for the away team
         location, # Home if the game was played at the home team's stadium, Neutral if in a neutral location
         result, # home team score - away team score
         total, # total points scored 
         overtime, # indicator for if the game went into OT
         home_rest, # number of days of rest the home team had since last game
         away_rest, # number of days of rest the away team had since last game
         home_moneyline, # used to calculate win prob for home team
         home_prob, # estimated win probability for the home team 
         spread_line, # points required to even the odds between the home team to the away team
         total_line, # expected total points
         div_game, # indicator for if the teams playing each other are in the same division. A more consequential game for standings.
         roof, # type of stadium roof, such as dome, closed, or outdoors.
         surface, # type of grass on the field
         temp, # outside temp if the stadium is outdoors 
         wind # speed of wind if the stadium is outdoors
         )
```
### Distance between NFL cities

This matrix of distances in miles will be use to determine the distances traveled (in miles) by the away team. Our hypothesis is that this may contribute to the higher rate loss for the away team.
```{r}
#data for distance between nfl cities
distance <- read.csv("https://raw.githubusercontent.com/joannarashid/nfl_reg_project/main/nfl_city_diatnces.csv")
#resetting index
rownames(distance) <- as.array(distance[,1])
distance <- distance[,-1]
#created variable for miles traveled by away team
for (i in 1:nrow(games_select)){
  x = games_select$away_team[i]
  y = games_select$home_team[i]
  games_select$traveled[i] <- distance[x,y]
}
```


## Model Analysis

### Analysis 1. Evaluating the spread line

First, as a gut check, a regression analysis will be run to evaluate the accuracy of `spread_line` as a predictor of the actual result of the game. Based on the plot below, there does appear to be a strong linear relationship. 

```{r}
ggplot(data=games_select, aes(x=spread_line, y=result)) +
  geom_point() +
  geom_smooth(method=lm) +
  ggtitle("Home Team Spread Line by Home Team Result")

```

Using `result` as the response variable and `spread_line` as the predicting variable, we would expect the regression forumula to indicate that the result plus the spread is zero without an intercept, meaning the coefficient of `spread_line` should be 1. 

```{r}
spread_model <- lm(result ~ spread_line + 0, data=games_select)
summary(spread_model)
```

```{r}
# is the coefficient for spread_line significantly equal to 1?
# Perform a t-test: Null Hypothesis is that B1 is NOT equal to 1. Alt Hypothesis is that B1 IS equal to 1. 
b1 <- coef(summary(spread_model))[,"Estimate"]
se <- coef(summary(spread_model))[,"Std. Error"]
t_val <- (b1 - 1.0) / se
print(paste("Is coeff = 1? p-value:", 2*pt(t_val, 2669, lower.tail = FALSE))) # FAIL to reject Null Hypothesis
confint(spread_model, level=0.95)
```


Indeed, the coefficient for `spread_line` is statistically significant, the overall regression is statistically significant, and there are no obvious violations of regression assumptions. At an alpha level of 0.05, the coefficient for `spread_line` is **not** statistically significantly equal to 1, but the confidence interval shows that it is likely between 0.96 and 1.12. It is also not statistically significantly less than or greater than 1 either.

It is reasonable to conclude that spread_line is a fairly accurate predictor of the result of a game, but the R-squared value is not particularly high. It would not be relevant as a controlling variable for evaluating home team advantage under the assumption that it takes into account home team advantage, which would mean controlling for it would remove the ability to identify home team advantage individually in our modeling.

-----

### Analysis 2. Home Field vs Neutral Field

Every year, there are a few regular season games that are played in a neutral location, usually overseas. The following regression analysis will evaluate if this factor (game played at home) is associated with a decrease in the result. The super bowl is also played in a neutral location, but this is excluded from the analysis because it is not a regular season game. Additionally, only seasons in which there actually were games of this type are included.

```{r}

seasons_with_neutral_games <- games_select %>%
  filter(game_type=="REG" & location == "Neutral") %>%
  group_by(season) %>%
  summarize(num_games=n())

games_reg <- games_select %>%
  filter(game_type=="REG") %>%
  inner_join(seasons_with_neutral_games, by="season") %>%
  mutate(location = as.factor(location))

neutral_model <- lm(result ~ location, data=games_reg)
summary(neutral_model)

```

```{r}
games_reg %>%
  group_by(location) %>%
  summarize(games=n())
```


The results of this regression analysis can be interpreted as comparing the average result at a game played at the "home" team's home field versus a game played at a neutral location. The negative coefficient for `locationNeutral` supports an association between playing a team at a neutral location and a decrease in the overall result of the game. The regression coefficient and the overall regression are significant at a 0.05 alpha level, but not at a 0.01 alpha level. There are only 31 games (~1%) that are played in a neutral location however. Additionally the R-squared for this model is extremely low. In summary, this model indicates that a more thorough analysis is needed.

To perform a more thorough analysis, additional predicting and controlling variables should be analyzed, with a focus on the regular season games that _are_ played at a home location.


### Analysis 3: Detailed Game-Level Predictors

For this analysis, the data will be reformatted to a structure that has the following key variables: `team`, `opponent`, `home` which will be a dummy variable set to 1 if the "team" is the home team, `team_score`, the end score of the "team", `opponent_score`, the end score of the "opponent", and `result`, the team_score minus the opponent_score. Each game will appear twice, once for each team and home and away. Other variables will be kept and assessed as predictor variables for additional analysis. Only regular season games will be considered.

Additionally, a controlling variable `point_diff` will be computed. This variable will be the weighted average point differential (team score - opponent score) for the "team" for that season, weighted ~50% in favor of the prior three games if there are 3 prior games. For the first 3 games of each season, the overall season point differential will be used, but a dummy variable will be added to indicate that this value is computed differently. 

```{r}
team_games_home <- games_select %>%
  filter(game_type=="REG" & location=="Home") %>%
  mutate(gameday=as.POSIXct(gameday),
         home=1) %>%
  select(season, week, gameday, weekday, gametime, traveled, team=home_team, opponent=away_team,
         home, team_score=home_score, opponent_score=away_score, result, 
         team_rest=home_rest, opponent_rest=away_rest,
         roof, surface, temp, wind)

# flip home and away stats
team_games_away <- games_select %>%
  filter(game_type=="REG" & location=="Home") %>%
  mutate(result_away=away_score-home_score,
         gameday=as.POSIXct(gameday),
         home=0) %>%
  select(season, week, gameday, weekday, gametime, traveled, team=away_team, opponent=home_team,
         home, team_score=away_score, opponent_score=home_score, result=result_away, 
         team_rest=away_rest, opponent_rest=home_rest,
         roof, surface, temp, wind)  
  
team_games <- rbind(team_games_home, team_games_away) %>%
  arrange(season, team, week) %>%
  group_by(season, team) %>%
  mutate(team_game_number = row_number()) # the team's Nth game in the season, not counting bye weeks

# a teams total point differential for the entire season
total_point_diff <- team_games %>%
  group_by(season, team) %>%
  summarise(total_point_diff = sum(result))

# computed weighted point diffs for each game. All seasons have 16 games each team.
team_games <- team_games %>% 
  mutate(last_three = ifelse(team_game_number>3,lag(result,1)+lag(result,2) + lag(result,3), NA)) %>%
  left_join(total_point_diff, by=c("season","team")) %>%
  mutate(
    weighted_point_diff = ifelse(
      team_game_number >3, ((last_three/3)*0.5) + (((total_point_diff-last_three)/13)*0.5), total_point_diff/16
    ),
    first_three_game = ifelse(
      team_game_number <= 3, 1, 0
    ),
    primetime_game = ifelse( # if game is Sunday Night Football or Monday Night Football
      weekday=="Monday" | (weekday=="Sunday" & hour(as.POSIXct(gametime, format="%H:%M")) >= 19), 1, 0
    ),
    outdoor_game = ifelse(
      roof=="outdoors" | roof=="open", 1, 0
    ),
    temp = ifelse(is.na(temp), 0, temp)
  ) %>%
  select(-last_three, -total_point_diff)
  

head(team_games)

  
```

**Simple Model**
The first linear regression model below will use `result` as the response variable and just `weighted_point_diff` and `home` as predicting variables to start.

```{r}
model1 <- lm(result ~ home + weighted_point_diff, data=team_games)
summary(model1)

```

```{r, fig.show="hold", out.width="50%"}
# basic residual analysis

plot(model1$fitted.values, model1$residuals, main="Fitted vs Residual")
qqPlot(model1$residuals, main="QQPlot Residuals")

```

The model is statistically significant overall, and the coefficient for home team is 4.65 and statistically significant, meaning that a team's score played at home is associated with an increase of 4.65 points, holding the weighted point differential constant. The  model does not seem to violate normality and constant variance assumptions badly, although there might be a slight tail to the residuals and a possible negative trend in variance. The R-squared value is relatively low, so adding additional predicting variables may help. However, the direction of the result is promising in confirming the home team advantage hypothesis at a high level.

Note: versions of this model removing the first three games or adding an interaction term for the weighted point differential and first three games did not significantly alter the results of this model. 

**Adding Predicting Variables**

```{r}

model2 <- lm(result ~ home + weighted_point_diff + team_rest + opponent_rest + primetime_game + outdoor_game + temp, data=team_games)

summary(model2)

```
```{r, fig.show="hold", out.width="50%"}
# basic residual analysis

plot(model2$fitted.values, model2$residuals, main="Fitted vs Residual")
qqPlot(model1$residuals, main="QQPlot Residuals")

```
The R-squared improved with the addition of several other variables, and the `home` variable is still statistically significant.
-----


Adding injury data: for this, we collected data on reported injuries, filtered out players who either never started or had questionable report statuses. The regression variable will be number of injured players on the home team and the away team.

```{r}
injuries <- load_injuries(c(2010:2019)) %>%
  mutate(season = as.integer(season))

rosters <- read.csv("https://raw.githubusercontent.com/leesharpe/nfldata/master/data/rosters.csv") %>%
  filter(season > 2009)


injuries_roster <- injuries %>%
  left_join(rosters, by=c("season"="season", "team"="team", "full_name"="full_name")) %>%
  select(season,
         week,
         team,
         full_name,  # injured player full name
         report_status, # player's status on the official injury report
         games, # from rosters, number of games played total during that season for that team
         starts, # from rosters, number of total starts during that season for that team
         years, # from rosters, number of years player has been in the NFL
         av # from rosters, the player's Approximate Value for that year as defined by the Pro Football Reference metric
         )

injury_counts <- injuries_roster %>%
  filter(report_status == 'Out' | report_status == 'Doubtful' | report_status == 'Questionable') %>%
  filter(starts > 0) %>%
  count(team, week, season) %>%
  mutate(week = as.integer(week))

df_combine <- team_games %>%
  left_join(injury_counts, by=c('season', 'week', 'team' = 'team')) %>%
  rename(n_injured_home = n) %>% # number of injured players on home team
  left_join(injury_counts, by=c('season', 'week', 'opponent' = 'team')) %>%
  rename(n_injured_away = n) %>% # number of injured players on away team
  replace_na(list(n_injured_away = 0, n_injured_home = 0))
```

Adding standings: using standings for current season would be "cheating" since it would include information about whether the team won or lost the game, but using the win rate for the previous season would be reasonable here. The limitation is that rosters do change from season to season.
```{r}
standings_raw <- read.csv("http://www.habitatring.com/standings.csv") %>%
  filter(season > 2008) %>%
  mutate(win_rate = wins/(wins + losses + ties)) %>%
  mutate(next_season = season + 1)
#str(standings_raw)
#str(games_select)
df_combine <- df_combine %>% 
  left_join(standings_raw %>% select(c('team', 'next_season', 'win_rate')), 
            by=c('team' = 'team', 'season' = 'next_season')) %>% 
  rename(home_wr_prev = win_rate) %>%
  left_join(standings_raw %>% select(c('team', 'next_season', 'win_rate')), 
            by=c('opponent' = 'team', 'season' = 'next_season')) %>% 
  rename(away_wr_prev = win_rate)
```

Fit the regression model again adding in all the new variables including: distance traveled, number of injured players on each team, and the win rate of each team in the previous season.
```{r R.options=list(max.print=20)}

model3 <- lm(result ~ home + weighted_point_diff + team_rest + opponent_rest + 
               primetime_game + outdoor_game + temp + n_injured_home + n_injured_away + 
               home_wr_prev + away_wr_prev + as.factor(team) + as.factor(opponent) + traveled,
              data=df_combine)

summary(model3)
```
From this model, it looks like the most relevant variables are which teams are playing each other, home, weighted_point_diff, number of injured players, and previous season win rates.
```{r, fig.show="hold", out.width="50%"}
# basic residual analysis

plot(model3$fitted.values, model3$residuals, main="Fitted vs Residual")
qqPlot(model3$residuals, main="QQPlot Residuals")

```
Another thing we were interested in looking at is how the home field advantage has changed over time, here we run regression models using the same variables as shown above, except we filter the data by year and then graph the coefficient of the `home` variable. It looks like the home field advantage has been significant from 2010-2018, on average yielding the home team 3-6 point differential advantage. However it shrank significantly in 2019 and 2020, though the home team is still very, very slightly advantaged.
```{r}
home_coeffs <-  list()
for(yr in c(2010:2020))
{
  fit <- lm(result ~ home + weighted_point_diff + team_rest + opponent_rest + 
              primetime_game + outdoor_game + temp + n_injured_home + 
              n_injured_away + home_wr_prev + away_wr_prev + traveled, 
              data=df_combine %>% filter(season == yr))
  home_coeffs <- append(home_coeffs, fit$coefficients['home'])
}
home_adv_df = tibble(season = c(2010:2020), home_adv = home_coeffs)
```

```{r}
p <- ggplot(data=home_adv_df, aes(x=as.factor(season), y=home_adv)) +
  geom_bar(stat="identity") +
  theme_minimal()
p
```

### Logistic Regression

This model uses 'home-win' as binary response variable, where a home-team win = 1 and a home-team loss = 0. The explanatory variables are the same as above. The goal here is to examine if there are any other variables which influence whether the home team is more or less likely to win.
```{r R.options=list(max.print=20)}
#adds a binary variable for home team win  1 = win, 0 = lose
df_combine$home_win <- ifelse(df_combine$result > 0, 1 , 0)

log_model <- glm(home_win ~ home + weighted_point_diff + team_rest + opponent_rest + 
               primetime_game + outdoor_game + temp + n_injured_home + n_injured_away + 
               home_wr_prev + away_wr_prev + as.factor(team) + as.factor(opponent) +
               traveled, data = df_combine, family = binomial(link = 'logit'))
summary(log_model)

#accuracy(log_home$fitted.values, games_select$home_win, 0.5)
```
Like the linear models, the only statistically significant variables in the logistic model are control variables.

### Effect of "fans in stands"

None of the  explanatory variables explored have proved to have relationship with home-team wins. However, there is still an anomaly in the data that can be analyzed. The phenomenon of home-team advantage appears to be declining in recent years. Anecdotally, home-team advantage is often attributed to the psycho-social effect of the cheers from fan when playing at home. The pandemic provides a useful natural experiment to test this hypothesis. In 2020 and 2021, games were played with no fans in the stands.


```{r}
#home wins an losses by year

games_select$home_win <- ifelse(games_select$result > 0, 1 , 0)
games_select$gameday <- as.Date(games_select$gameday, "%Y-%m-%d")

games_select$year <- format(as.Date(games_select$gameday, format="%Y/%m/%d"),"%Y")

ggplot(games_select, 
       aes(x = year, fill = as.factor(home_win) ))+ 
  geom_bar(position = position_dodge(preserve = "single"))

```
Here we have created a binary variable for games played with no fans in the stands and use it as an explanatory variable in a logistic regression.
```{r}
#create binary variable for pandemic
df_combine$pandemic <- ifelse(df_combine$season == 2020, 1 , 0)
games_select$pandemic <- ifelse(games_select$season == 2020, 1 , 0)

pandemic_log_model <- glm(home_win ~ pandemic, data = df_combine, family = binomial(link = 'logit'))
summary(pandemic_log_model)
```

```{r R.options=list(max.print=20)}
full_log_model_pandemic <- glm(home_win ~ home + weighted_point_diff + team_rest + opponent_rest + 
               primetime_game + outdoor_game + temp + n_injured_home + n_injured_away + 
               home_wr_prev + away_wr_prev + as.factor(team) + as.factor(opponent) +
               traveled + pandemic, data = df_combine, family = binomial(link = 'logit'))
summary(full_log_model_pandemic)
```

This regression suggest that the log-odds of a home-team win are reduced by -.257 when no fans are in the stands giving credence to the assertion that the support of fans improves the teams' performance. However, when we include this variable in a regression with all other explanatory variables, 'pandemic' is not significant.

### Random Forest

Running a random forest regression model will achieve optimal predictability however, this comes at the cost of gaining insights from our data.  We will create a "black box" if you will and will be difficult to explain specific effects and determine why an outcome is the way it is.
```{r}

set.seed(1)
# only pull columns with data
RemoveNA = 
  #df_combine 
  games_select %>% 
  select_if(~ !any(is.na(.)))

# convert indicators to factors
RemoveNA$home_win = as.factor(RemoveNA$home_win)
RemoveNA$overtime = as.factor(RemoveNA$overtime)
RemoveNA$div_game = as.factor(RemoveNA$div_game)

# create train and test set 75% split

train_rf <- RemoveNA %>%
  select(home_win,season , weekday , gametime , away_team , home_team , overtime , home_rest , away_rest , div_game , roof , surface , pandemic , spread_line)


RF_Fit1.rf <- randomForest(home_win ~ season + weekday + gametime + away_team + home_team + overtime + home_rest + away_rest + div_game + roof + surface + pandemic + spread_line, data = train_rf, importance = TRUE, mtry=1, ntree=500)

RF_Fit2.rf <- randomForest(home_win ~ season + weekday + gametime + away_team + home_team + overtime + home_rest + away_rest + div_game + roof + surface + pandemic + spread_line, data = train_rf, importance = TRUE, mtry=2, ntree=500)

RF_Fit4.rf <- randomForest(home_win ~ season + weekday + gametime + away_team + home_team + overtime + home_rest + away_rest + div_game + roof + surface + pandemic + spread_line, data = train_rf, importance = TRUE, mtry=4, ntree=500)

RF_Fit7.rf <- randomForest(home_win ~ season + weekday + gametime + away_team + home_team + overtime + home_rest + away_rest + div_game + roof + surface + pandemic + spread_line, data = train_rf, importance = TRUE, mtry=7, ntree=500)


RF_Fit13.rf <- randomForest(home_win ~ season + weekday + gametime + away_team + home_team + overtime + home_rest + away_rest + div_game + roof + surface + pandemic + spread_line, data = train_rf, importance = TRUE, mtry=13, ntree=500)

RF_Fit1.rf
RF_Fit2.rf
RF_Fit4.rf
RF_Fit7.rf
RF_Fit13.rf

```

The best mtry (number of predictors sampled for spliting at each node) was mtry = 2 with an OOB estimate of 36.29
```{r}
RF_Fit2.rf
RF_Fit2.rf$err.rate[500,1]
```

Plotting the model will help us visualize the OOB error rate (black line) as trees are averaged across.  This will show us that our error rate stabilizes with around 75 trees and slowly decreases therefore after.


```{r}
plot(RF_Fit2.rf)
```

let's try to determine feature importance
```{r}
importance(RF_Fit2.rf)
```

Visualizing the importance of features against accuracy, we notice that spread_line is of most importance in determining if home team wins or not, remember this is our control variable to determine if the team is good or not.  
```{r}
varImpPlot(RF_Fit2.rf,type=2)
```

The OOB estimate of error rate is 36.29%, which is only slightly better than random guessing... not too great.
```{r}
RF_Fit2.rf
```

# Results

### Linear Models
```{r warning=FALSE}
r_table <- data.frame(Model = c("Model1", 
                                "Model2", 
                                "Model3"),
                      R2 = c(summary(model1)$r.squared,
                             summary(model2)$r.squared,
                             summary(model3)$r.squared),
                      Adj_R2 = c(summary(model1)$adj.r.squared,
                                 summary(model2)$adj.r.squared,
                                 summary(model3)$adj.r.squared),
                      Num_Vars = c(length(model1$coefficients)-1,
                                   length(model2$coefficients)-1,
                                   length(model3$coefficients)-1),
                      MSE = c(mean((model1$fitted.values - df_combine$result)^2),
                              mean((model2$fitted.values - df_combine$result)^2),
                              mean((model3$fitted.values - df_combine$result)^2)),
                      SSE = c(sum((model1$fitted.values - df_combine$result)^2),
                              sum((model2$fitted.values - df_combine$result)^2),
                              sum((model3$fitted.values - df_combine$result)^2)),
                      MAE = c(mean(abs(model1$fitted.values - df_combine$result)),
                              mean(abs(model2$fitted.values - df_combine$result)),
                              mean(abs(model3$fitted.values - df_combine$result))))
r_table
```
### Logistic Model
```{r}
log_table <- data.frame(Model = c("Logistic Model",
                                "Pandemic Model", 
                                "Pandemic Full Model"),
                      AIC = c(log_model$aic,
                             pandemic_log_model$aic,
                             full_log_model_pandemic$aic),
                      Deviance = c(log_model$deviance,
                             pandemic_log_model$deviance,
                             full_log_model_pandemic$deviance),
                      Num_Vars = c(length(log_model$coefficients)-1,
                                   length(pandemic_log_model$coefficients)-1,
                                   length(full_log_model_pandemic$coefficients)-1))
log_table
```

### Random Forest Model
```{r}
rf_table <- data.frame(Model = c("mtry1", 
                                "mtry2", 
                                "mtry4",
                                "mtry7",
                                "mtry13"),
                      OOB = c(RF_Fit1.rf$err.rate[500,1],
                             RF_Fit2.rf$err.rate[500,1],
                             RF_Fit4.rf$err.rate[500,1],
                             RF_Fit7.rf$err.rate[500,1],
                             RF_Fit13.rf$err.rate[500,1]))
rf_table
```

# Conclusion

Predicting the outcome of NFL games, whether regressing on the point differential or using logistic regression on win or loss turned out to be not so trivial of a task. None of the linear or logistic regression models tested had the greatest fit.Using a Random Forest to obtain a model for highest prediction accuracy was a good idea early on in the project, however we found that the accuracy of a random forest model, which we expected to have a large advantage over regression models, was not significant enough.  The out of box error we arrived at for random forest was about 36%.  This means that the model is not much better than a random guess at predicting home wins.  The model error gives our variable importance analysis results some ambiguity.  Ideally, we would have achieve a much higher accuracy rate thus giving us more confidence in the features that are significant/important toward home-wins.

In terms of whether or not home field advantage is significant, our findings agree with existing literature which suggest that it is. We were also able to observe that the home field advantage has a sharp drop off in 2019 and 2020. In 2020, this can at least partially attributed to the lack of fans in the stands. Other relevant factors which seemed to have statistically relevant effect on win/loss in regression models besides home field advantage were number of injured players on each team, the performance of each team in the previous season, and the weighted point differential of each team in their last three games.


# References

### Data Sources
2021 NFL Game Data. (n.d.). Retrieved from http://www.habitatring.com/

NFL Football Stadiums - Quest for 31. (n.d.). Retrieved from http://www.nflfootballstadiums.com/

Nflverse. (Sharpe, Lee). Nfldata/rosters.csv at master · nflverse/nfldata. Retrieved from https://github.com/nflverse/nfldata/blob/master/data/rosters.csv

### Literature
Cleveland, T. (2021, September 14). Numbers that matter for predicting NFL win totals: Sharp Football. Retrieved from https://www.sharpfootballanalysis.com/betting/numbers-that-matter-for-predicting-nfl-win-totals-part-one/

Jamieson, J. P. (2010). The Home Field Advantage in Athletics: A Meta-Analysis. Journal of Applied Social Psychology, 40(7), 1819-1848. doi:10.1111/j.1559-1816.2010.00641.x

Kilgore, A., & Greenberg, N. (2022, January 15). Analysis | NFL home-field advantage was endangered before the pandemic. Now it's almost extinct. Retrieved from https://www.washingtonpost.com/sports/2022/01/14/nfl-home-field-advantage-pandemic/

Mccarrick, D., Bilalic, M., Neave, N., & Wolfson, S. (2021). Home advantage during the COVID-19 pandemic: Analyses of European football leagues. Psychology of Sport and Exercise, 56, 102013. doi:10.1016/j.psychsport.2021.102013

Ponzo, M., & Scoppa, V. (2014). Does the Home Advantage Depend on Crowd Support? Evidence from Same-Stadium Derbies. SSRN Electronic Journal. doi:10.2139/ssrn.2426859

Swartz, T. B., & Arce, A. (2014). New Insights Involving the Home Team Advantage. International Journal of Sports Science &amp; Coaching, 9(4), 681-692. doi:10.1260/1747-9541.9.4.681

